{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/fanbyprinciple/gpt3-notebook?scriptVersionId=84122419\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"code","source":"!pip install openai","metadata":{"execution":{"iopub.status.busy":"2022-01-01T08:59:27.836571Z","iopub.execute_input":"2022-01-01T08:59:27.836911Z","iopub.status.idle":"2022-01-01T08:59:42.557449Z","shell.execute_reply.started":"2022-01-01T08:59:27.836878Z","shell.execute_reply":"2022-01-01T08:59:42.556428Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting openai\n  Downloading openai-0.11.5.tar.gz (466 kB)\n     |████████████████████████████████| 466 kB 911 kB/s            \n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: requests>=2.20 in /opt/conda/lib/python3.7/site-packages (from openai) (2.25.1)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from openai) (4.62.3)\nRequirement already satisfied: pandas>=1.2.3 in /opt/conda/lib/python3.7/site-packages (from openai) (1.3.4)\nCollecting pandas-stubs>=1.1.0.11\n  Downloading pandas_stubs-1.2.0.39-py3-none-any.whl (161 kB)\n     |████████████████████████████████| 161 kB 12.6 MB/s            \n\u001b[?25hCollecting openpyxl>=3.0.7\n  Downloading openpyxl-3.0.9-py2.py3-none-any.whl (242 kB)\n     |████████████████████████████████| 242 kB 12.3 MB/s            \n\u001b[?25hCollecting et-xmlfile\n  Downloading et_xmlfile-1.1.0-py3-none-any.whl (4.7 kB)\nRequirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas>=1.2.3->openai) (2.8.0)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas>=1.2.3->openai) (2021.3)\nRequirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.7/site-packages (from pandas>=1.2.3->openai) (1.19.5)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from pandas-stubs>=1.1.0.11->openai) (3.10.0.2)\nRequirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests>=2.20->openai) (4.0.0)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.20->openai) (1.26.7)\nRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.20->openai) (2.10)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.20->openai) (2021.10.8)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas>=1.2.3->openai) (1.16.0)\nBuilding wheels for collected packages: openai\n  Building wheel for openai (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for openai: filename=openai-0.11.5-py3-none-any.whl size=161463 sha256=e5a761f37d8c78f3d20619f07ea710d768429c85758ca29ec4a419b4820f3721\n  Stored in directory: /root/.cache/pip/wheels/5a/52/66/06c234d9748d81b9622d0b9765c3bd10e99d059ed93f13b0b3\nSuccessfully built openai\nInstalling collected packages: et-xmlfile, pandas-stubs, openpyxl, openai\nSuccessfully installed et-xmlfile-1.1.0 openai-0.11.5 openpyxl-3.0.9 pandas-stubs-1.2.0.39\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"\n\"\"\"Creates the Example and GPT classes for a user to interface with the OpenAI\nAPI.\"\"\"\n\nimport openai\nimport uuid\n\n\ndef set_openai_key(key):\n    \"\"\"Sets OpenAI key.\"\"\"\n    openai.api_key = key\n\n\nclass Example:\n    \"\"\"Stores an input, output pair and formats it to prime the model.\"\"\"\n    def __init__(self, inp, out):\n        self.input = inp\n        self.output = out\n        self.id = uuid.uuid4().hex\n\n    def get_input(self):\n        \"\"\"Returns the input of the example.\"\"\"\n        return self.input\n\n    def get_output(self):\n        \"\"\"Returns the intended output of the example.\"\"\"\n        return self.output\n\n    def get_id(self):\n        \"\"\"Returns the unique ID of the example.\"\"\"\n        return self.id\n\n    def as_dict(self):\n        return {\n            \"input\": self.get_input(),\n            \"output\": self.get_output(),\n            \"id\": self.get_id(),\n        }\n\n\nclass GPT:\n    \"\"\"The main class for a user to interface with the OpenAI API.\n    A user can add examples and set parameters of the API request.\n    \"\"\"\n    def __init__(self,\n                 engine='davinci',\n                 temperature=0.5,\n                 max_tokens=100,\n                 input_prefix=\"input: \",\n                 input_suffix=\"\\n\",\n                 output_prefix=\"output: \",\n                 output_suffix=\"\\n\\n\",\n                 append_output_prefix_to_query=False):\n        self.examples = {}\n        self.engine = engine\n        self.temperature = temperature\n        self.max_tokens = max_tokens\n        self.input_prefix = input_prefix\n        self.input_suffix = input_suffix\n        self.output_prefix = output_prefix\n        self.output_suffix = output_suffix\n        self.append_output_prefix_to_query = append_output_prefix_to_query\n        self.stop = (output_suffix + input_prefix).strip()\n\n    def add_example(self, ex):\n        \"\"\"Adds an example to the object.\n        Example must be an instance of the Example class.\n        \"\"\"\n        assert isinstance(ex, Example), \"Please create an Example object.\"\n        self.examples[ex.get_id()] = ex\n\n    def delete_example(self, id):\n        \"\"\"Delete example with the specific id.\"\"\"\n        if id in self.examples:\n            del self.examples[id]\n\n    def get_example(self, id):\n        \"\"\"Get a single example.\"\"\"\n        return self.examples.get(id, None)\n\n    def get_all_examples(self):\n        \"\"\"Returns all examples as a list of dicts.\"\"\"\n        return {k: v.as_dict() for k, v in self.examples.items()}\n\n    def get_prime_text(self):\n        \"\"\"Formats all examples to prime the model.\"\"\"\n        return \"\".join(\n            [self.format_example(ex) for ex in self.examples.values()])\n\n    def get_engine(self):\n        \"\"\"Returns the engine specified for the API.\"\"\"\n        return self.engine\n\n    def get_temperature(self):\n        \"\"\"Returns the temperature specified for the API.\"\"\"\n        return self.temperature\n\n    def get_max_tokens(self):\n        \"\"\"Returns the max tokens specified for the API.\"\"\"\n        return self.max_tokens\n\n    def craft_query(self, prompt):\n        \"\"\"Creates the query for the API request.\"\"\"\n        q = self.get_prime_text(\n        ) + self.input_prefix + prompt + self.input_suffix\n        if self.append_output_prefix_to_query:\n            q = q + self.output_prefix\n\n        return q\n\n    def submit_request(self, prompt):\n        \"\"\"Calls the OpenAI API with the specified parameters.\"\"\"\n        response = openai.Completion.create(engine=self.get_engine(),\n                                            prompt=self.craft_query(prompt),\n                                            max_tokens=self.get_max_tokens(),\n                                            temperature=self.get_temperature(),\n                                            top_p=1,\n                                            n=1,\n                                            stream=False,\n                                            stop=self.stop)\n        return response\n\n    def get_top_reply(self, prompt):\n        \"\"\"Obtains the best result as returned by the API.\"\"\"\n        response = self.submit_request(prompt)\n        return response['choices'][0]['text']\n\n    def format_example(self, ex):\n        \"\"\"Formats the input, output pair.\"\"\"\n        return self.input_prefix + ex.get_input(\n        ) + self.input_suffix + self.output_prefix + ex.get_output(\n        ) + self.output_suffix\n","metadata":{"execution":{"iopub.status.busy":"2022-01-01T08:59:42.560753Z","iopub.execute_input":"2022-01-01T08:59:42.561027Z","iopub.status.idle":"2022-01-01T08:59:42.598532Z","shell.execute_reply.started":"2022-01-01T08:59:42.560982Z","shell.execute_reply":"2022-01-01T08:59:42.597093Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import json\nimport openai","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-01T09:00:03.559437Z","iopub.execute_input":"2022-01-01T09:00:03.560081Z","iopub.status.idle":"2022-01-01T09:00:03.564373Z","shell.execute_reply.started":"2022-01-01T09:00:03.560029Z","shell.execute_reply":"2022-01-01T09:00:03.563724Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"You can get your openai keys from here: https://beta.openai.com/account/api-keys","metadata":{}},{"cell_type":"code","source":"import getpass\ncity = getpass.getpass('Input your open ai service key:')","metadata":{"execution":{"iopub.status.busy":"2022-01-01T09:06:07.10372Z","iopub.execute_input":"2022-01-01T09:06:07.104701Z","iopub.status.idle":"2022-01-01T09:06:21.321165Z","shell.execute_reply.started":"2022-01-01T09:06:07.104646Z","shell.execute_reply":"2022-01-01T09:06:21.320181Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdin","text":"Input your open ai service key: ···················································\n"}]},{"cell_type":"code","source":"openai.api_key = city","metadata":{"execution":{"iopub.status.busy":"2022-01-01T09:07:06.348864Z","iopub.execute_input":"2022-01-01T09:07:06.349217Z","iopub.status.idle":"2022-01-01T09:07:06.353379Z","shell.execute_reply.started":"2022-01-01T09:07:06.349183Z","shell.execute_reply":"2022-01-01T09:07:06.352418Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Application 1 - Directly use as chatbot Use-case\ngpt1 = GPT(engine=\"davinci\", temperature=0.2, max_tokens=100)\nprompt1 = \"How to learn data science?\"\noutput1 = gpt1.submit_request(prompt1)\noutput1.choices[0].text","metadata":{"execution":{"iopub.status.busy":"2022-01-01T09:15:44.431836Z","iopub.execute_input":"2022-01-01T09:15:44.432544Z","iopub.status.idle":"2022-01-01T09:15:49.058596Z","shell.execute_reply.started":"2022-01-01T09:15:44.432497Z","shell.execute_reply":"2022-01-01T09:15:49.057623Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"'\\nI have been asked this question many times. I have been asked this question many times.\\n\\nI have been asked this question many times.\\n\\nI have been asked this question many times.\\n\\nI have been asked this question many times.\\n\\nI have been asked this question many times.\\n\\nI have been asked this question many times.\\n\\nI have been asked this question many times.\\n\\nI have been asked this question many times.\\n\\nI have'"},"metadata":{}}]},{"cell_type":"code","source":"# Application 2 - LaTex Use-case - Text to Equation\ngpt2 = GPT(engine=\"davinci\", temperature=0.5, max_tokens=100)\n# Directly use as chatbot\ngpt2.add_example(Example('Two plus two equals four', '2 + 2 = 4'))\ngpt2.add_example(Example('The integral from zero to infinity', '\\\\int_0^{\\\\infty}'))\ngpt2.add_example(Example('The gradient of x squared plus two times x with respect to x', '\\\\nabla_x x^2 + 2x'))\ngpt2.add_example(Example('The log of two times x', '\\\\log{2x}'))\ngpt2.add_example(Example('x squared plus y squared plus equals z squared', 'x^2 + y^2 = z^2'))","metadata":{"execution":{"iopub.status.busy":"2022-01-01T09:16:07.010099Z","iopub.execute_input":"2022-01-01T09:16:07.010455Z","iopub.status.idle":"2022-01-01T09:16:07.018005Z","shell.execute_reply.started":"2022-01-01T09:16:07.010415Z","shell.execute_reply":"2022-01-01T09:16:07.017102Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"prompt2 = \"x squared plus 2 times x\"\noutput2 = gpt2.submit_request(prompt2)\noutput2.choices[0].text","metadata":{"execution":{"iopub.status.busy":"2022-01-01T09:16:22.995541Z","iopub.execute_input":"2022-01-01T09:16:22.996483Z","iopub.status.idle":"2022-01-01T09:16:24.326924Z","shell.execute_reply.started":"2022-01-01T09:16:22.99643Z","shell.execute_reply":"2022-01-01T09:16:24.325914Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"'output: x^2 + 2x\\n\\n'"},"metadata":{}}]},{"cell_type":"code","source":"# Application 3 - Translator Use-case\ngpt3 = GPT(engine=\"davinci\", temperature=0.5, max_tokens=100)\ngpt3.add_example(Example('What is your name?', 'quel est votre nom?'))\ngpt3.add_example(Example('What are you doing?', 'Que faites-vous?'))\ngpt3.add_example(Example('How are you?', 'Comment allez-vous?'))","metadata":{"execution":{"iopub.status.busy":"2022-01-01T09:16:38.069405Z","iopub.execute_input":"2022-01-01T09:16:38.069712Z","iopub.status.idle":"2022-01-01T09:16:38.074923Z","shell.execute_reply.started":"2022-01-01T09:16:38.06968Z","shell.execute_reply":"2022-01-01T09:16:38.074202Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"prompt3 = \"where are you?\"\noutput3 = gpt3.submit_request(prompt3)\noutput3.choices[0].text","metadata":{"execution":{"iopub.status.busy":"2022-01-01T09:17:08.536794Z","iopub.execute_input":"2022-01-01T09:17:08.53731Z","iopub.status.idle":"2022-01-01T09:17:09.838035Z","shell.execute_reply.started":"2022-01-01T09:17:08.537271Z","shell.execute_reply":"2022-01-01T09:17:09.836872Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"'output: Où êtes-vous?\\n\\n'"},"metadata":{}}]},{"cell_type":"markdown","source":"# Lets try and train this model for producing ","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}